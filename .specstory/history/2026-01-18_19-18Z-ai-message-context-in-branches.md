<!-- Generated by SpecStory, Markdown v2.1.0 -->

<!-- cursor Session adfa2238-2e2a-41d8-846c-b40e02bd2955 (2026-01-18 19:18Z) -->

# AI message context in branches (2026-01-18 19:18Z)

_**User (2026-01-18 16:02Z)**_

Inside the same branch if I send several message what amount of context is sent to the AI? Just current message or summarization of current node content

---

_**Agent (model gpt-5.2, mode Ask)**_

<think><details><summary>Thought Process</summary>
**Explaining context handling**

I need to clarify how context works in a conversation with the AI. Typically, when a conversation is threaded, the AI receives the conversation history leading up to a specific branch, which may involve summarization. Cursor uses a "context window" that includes recent messages, summaries, and attachments. I should note that there are token limits, which means older messages might be summarized or omitted as needed. Each message includes not just the current message but also relevant prior context. I'll keep it concise.</details></think>

---

Inside the same branch/thread, the model typically receives **more than just your current message**.

### What’s usually sent
- **The current message** (always).
- **Conversation history on that branch** (your earlier messages + the assistant replies), **up to a token/context limit**.
- **Tool-provided “state/context”** the client may attach (commonly: selected/open files, snippets, diffs, errors, etc.), depending on your settings and what you’ve shared.

### What happens when the thread gets long
Because there’s a fixed **context window** (token budget), older parts of the branch will be handled in one of these ways:
- **Included verbatim** (if there’s room).
- **Summarized/condensed** (to save tokens).
- **Dropped entirely** (if still too large).

So the practical answer is: **it’s the current message + as much of the branch history/state as fits**; long branches often become **partly summarized** rather than sending the full “current node content” verbatim.

If you tell me what app you mean (Cursor chat, ChatGPT, another tool) and which model, I can be more specific about how it behaves and how to verify what’s being included.

---

_**User (2026-01-18 16:02Z)**_

But in my current codebase

---

_**Agent (model gpt-5.2, mode Ask)**_



---

In **your current Cursor codebase/workspace**, the AI is **not automatically sent your whole repo**.

### What context it likely gets (in your setup)
- **Your current chat thread on that branch** (recent messages + replies, until the context limit).
- **Auto-attached IDE state** (like what you see in the `<additional_data>` block): which files are open/recent, cursor position, sometimes terminal output, and sometimes selected text.
- **Only the file contents you explicitly include** (by selecting text, attaching a file, or using “include/open file” features). Otherwise the model just sees *metadata* like “`src/App.jsx (2209 lines)`”, not the full file.

### So: “current message” vs “summary of node”
- It’s **current message + as much prior branch history as fits**; if the thread grows, older parts may be **condensed/summarized** or dropped.
- **There is no automatic “summarization of your entire current codebase”** being sent—unless you or the tool explicitly provide it.

If you tell me whether you’re using **Cursor Ask** vs **Agent**, I can explain the practical difference: Agent can read files/tools to pull more context; Ask typically relies much more on what you paste/attach.

---

